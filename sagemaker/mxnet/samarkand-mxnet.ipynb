{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Apache MXNet and Gluon\n",
    "\n",
    "This tutorial shows how to train and test a Sentiment Analysis (Text Classification) model on Amazon SageMaker using Apache MXNet and the Gluon API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create needed directories\n",
    "\n",
    "We will data directory for the ready-to-use dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Standardized dataset\n",
    "\n",
    "As a prerequisite, we should have ran the [preprocessing notebook](../PreprocessNotebook.ipynb).\n",
    "\n",
    "Then, we will create the variables with routes to the needed directories.\n",
    "\n",
    "Finally, we will also download the dataset from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'data'\n",
    "test_dataset_file_name = '../data/preprocessed/sentiments-preprocessed-lemmatizing-test-10percent-dataset.csv'\n",
    "train_dataset_file_name = '../data/preprocessed/sentiments-preprocessed-lemmatizing-train-10percent-dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dataset\n",
    "\n",
    "We need a dataset with each line being space separated tokens, with the first token being the label: 1 for positive and\n",
    "0 for negative, and the second token our messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def convert_into_space_separated (dataset_file_name, destination_file_name):\n",
    "    output_data = list()\n",
    "    with open(dataset_file_name, newline='') as csv_file:\n",
    "        input_data = list(csv.reader(csv_file))\n",
    "\n",
    "        for message in input_data:\n",
    "            output_data.append(f'{message[0]} {message[1]}\\n')\n",
    "\n",
    "    with open(f'{data_directory}/{destination_file_name}', mode='w') as output_file:\n",
    "        for line in output_data:\n",
    "            output_file.writelines(line)\n",
    "\n",
    "convert_into_space_separated(train_dataset_file_name, 'train')\n",
    "convert_into_space_separated(test_dataset_file_name, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data\n",
    "\n",
    "We use the `sagemaker.s3.S3Uploader` to upload our datasets to an Amazon S3 location. The return value `inputs`\n",
    "identifies the location -- we use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import s3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "inputs = s3.S3Uploader.upload('data', 's3://{}/mxnet-gluon-sentiment-example/data'.format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the training function\n",
    "\n",
    "We need to provide a training script that can run on the SageMaker platform. The training scripts are essentially the same as one you would write for local training, but you can also access useful properties about the training environment through various environment variables. In addition, hyperparameters are passed to the script as arguments. For more about writing an MXNet training script for use with SageMaker, see [the SageMaker documentation](https://sagemaker.readthedocs.io/en/stable/using_mxnet.html#prepare-an-mxnet-training-script).\n",
    "\n",
    "The script here is a simplified implementation of [\"Bag of Tricks for Efficient Text Classification\"](https://arxiv.org/abs/1607.01759), as implemented by Facebook's [FastText](https://github.com/facebookresearch/fastText/) for text classification. The model maps each word to a vector and averages vectors of all the words in a sentence to form a hidden representation of the sentence, which is inputted to a softmax classification layer. For more details, please refer to [the paper](https://arxiv.org/abs/1607.01759).\n",
    "\n",
    "At the end of every epoch, our script also checks the validation accuracy, and checkpoints the best model so far, along with the optimizer state, in the folder `/opt/ml/checkpoints`. (If the folder `/opt/ml/checkpoints` does not exist, this checkpointing step is skipped.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize 'mxnet_sentiment.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a SageMaker training job\n",
    "\n",
    "The `MXNet` class allows us to run our training function on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. In this case we run our training job on a single `c4.2xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "m = MXNet('mxnet_sentiment.py',\n",
    "          role=get_execution_role(),\n",
    "          instance_count=1,\n",
    "          instance_type='ml.m5.large',\n",
    "          framework_version='1.8.0',\n",
    "          py_version='py37',\n",
    "          distribution={'parameter_server': {'enabled': True}},\n",
    "          hyperparameters={'batch-size': 8,\n",
    "                           'epochs': 2,\n",
    "                           'learning-rate': 0.01,\n",
    "                           'embedding-size': 50, \n",
    "                           'log-interval': 1000},\n",
    "          metric_definitions=[\n",
    "                   {'Name': 'training:accuracy', 'Regex': '\\[Epoch ([0-9]*)\\] Training: accuracy=([0-9].[0-9]*)'},\n",
    "                   {'Name': 'validation:accuracy', 'Regex': '\\[Epoch ([0-9]*)\\] Validation: accuracy=([0-9].[0-9]*)'},\n",
    "                   {'Name': 'validation:f1', 'Regex': '\\[Epoch ([0-9]*)\\] Validation: f1=([0-9].[0-9]*)'},\n",
    "                   {'Name': 'validation:precision', 'Regex': '\\[Epoch ([0-9]*)\\] Validation: Precision=([0-9].[0-9]*)'},\n",
    "                   {'Name': 'validation:recall', 'Regex': '\\[Epoch ([0-9]*)\\] Validation: Recall=([0-9].[0-9]*)'}\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `MXNet` estimator, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the logs, we can see our model's accuracy percentage on the test set using the above hyperparameters.\n",
    "\n",
    "After training, we use our `MXNet` object to build and deploy an `MXNetPredictor` object. This creates a SageMaker Endpoint that we can use to perform inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our predictor, we can perform inference on a JSON-encoded string array. \n",
    "\n",
    "The predictor runs inference on our input data and returns an array containing, for each inference, the original message, the predicted sentiment (1 for positive and 0 for negative), and the prediction probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [\"i feel good\",\n",
    "        \"i feel bad\",\n",
    "        \"More bike riding, but this time with a body guard and guide\",\n",
    "        \"Turtles are better than my Mac - lasts longer and moves faster\",\n",
    "        \"just got back from another camp get together! yay school got moved to next week! OMG ROADTRIP. hahaha more plans for me then!\",\n",
    "        \"Work is terrible  I need a break.\",\n",
    "        \"I didn't win but I didn't lose though. Drinking time!\",\n",
    "        \"is really wobbly again after a really good morning. I hate this\",\n",
    "        \"Kinda wish I never went back to bed this morning.. hmm... still feel good to have no real commitments today\",\n",
    "        \"Leaving home to come back to Ontario and not too happy about it!  I miss my family\",\n",
    "        \"I'm busily hunting for a summer job and a place to move into in August \",\n",
    "        \"I'm wondering if my girlfriend does crap on purpose to make me feel insignificant. I really hate that.\"\n",
    "       ]\n",
    "\n",
    "response = predictor.predict(data)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}